{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Vision Sytems: Session 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Today:\n",
    "\n",
    "### 1: Solution Assignment 1\n",
    "### 2: Learning and Optimization\n",
    "### 3: Multi-Layer Perceptron (MLP)\n",
    "### 4: Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colab tips:\n",
    "    - https://medium.com/@oribarel/getting-the-most-out-of-your-google-colab-2b0585f82403\n",
    "    - https://medium.com/datadriveninvestor/speed-up-your-image-training-on-google-colab-dc95ea1491cf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Solution Assignment 1\n",
    "\n",
    "By Salih Marangoz and Elif Cansu Yildiz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Learning and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Convolutional Networks (CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading and Loading Dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(),download=True)\n",
    " \n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting data loaders for iterating\n",
    "B_SIZE = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=B_SIZE, \n",
    "                                           shuffle=True) \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=B_SIZE, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\" \n",
    "    Varation of LeNet: a simple CNN model\n",
    "    for handwritten digit recognition\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Model initializer \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # layer 1\n",
    "        conv1 = nn.Conv2d(in_channels=1, out_channels=16,  kernel_size=5, stride=1, padding=0)\n",
    "        relu1 = nn.ReLU()\n",
    "        maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.layer1 = nn.Sequential(\n",
    "                conv1, relu1, maxpool1\n",
    "            )\n",
    "      \n",
    "        # layer 2\n",
    "        conv2 = nn.Conv2d(in_channels=16, out_channels=32,  kernel_size=5, stride=1, padding=0)\n",
    "        relu2 = nn.ReLU()\n",
    "        maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.layer2 = nn.Sequential(\n",
    "                conv2, relu2, maxpool2\n",
    "            )\n",
    "        \n",
    "        # fully connected classifier\n",
    "        in_dim = 32 * 4 * 4\n",
    "        self.fc = nn.Linear(in_features=in_dim, out_features=10)\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass \"\"\"\n",
    "        cur_b_size = x.shape[0]\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.layer2(out1)\n",
    "        out2_flat = out2.view(cur_b_size, -1)\n",
    "        y = self.fc(out2_flat)\n",
    "        return y\n",
    "    \n",
    "def count_model_params(model):\n",
    "    \"\"\" Counting the number of learnable parameters in a nn.Module \"\"\"\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "params = count_model_params(cnn)\n",
    "print(f\"Model has {params} learnable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 3e-4\n",
    "EPOCHS = 100\n",
    "EVAL_FREQ = 1\n",
    "SAVE_FREQ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    \"epoch\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"valid_loss\": [],\n",
    "    \"accuracy\": []\n",
    "}\n",
    "init_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(params=cnn.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(model):\n",
    "    \"\"\" Computing model accuracy \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_list = []\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "                 \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "            \n",
    "        # Get predictions from the maximum value\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += len( torch.where(preds==labels)[0] )\n",
    "        total += len(labels)\n",
    "                 \n",
    "    # Total correct predictions and loss\n",
    "    accuracy = correct / total * 100\n",
    "    loss = np.mean(loss_list)\n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, epoch, stats):\n",
    "    \"\"\" Saving model checkpoint \"\"\"\n",
    "    \n",
    "    if(not os.path.exists(\"models\")):\n",
    "        os.makedirs(\"models\")\n",
    "    savepath = f\"models/checkpoint_epoch_{epoch}.pth\"\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'stats': stats\n",
    "    }, savepath)\n",
    "    return\n",
    "\n",
    "\n",
    "def load_model(model, optimizer, savepath):\n",
    "    \"\"\" Loading pretrained checkpoint \"\"\"\n",
    "    \n",
    "    checkpoint = torch.load(savepath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    stats = checkpoint[\"stats\"]\n",
    "    \n",
    "    return model, optimizer, epoch, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model \n",
    "savepath = os.path.join(os.getcwd(), \"models\", \"checkpoint_epoch_70.pth\")\n",
    "model, optimizer, init_epoch, stats = load_model(cnn, optimizer, savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "\n",
    "for epoch in range(init_epoch, EPOCHS):\n",
    "    loss_list = []\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for i, (images, labels) in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = cnn(images)\n",
    "         \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "         \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "         \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1} Iter {i+1}: loss {loss.item():.5f}. \")\n",
    "             \n",
    "    loss_hist.append(np.mean(loss_list))\n",
    "    stats[\"epoch\"].append(epoch)\n",
    "    stats[\"train_loss\"].append(loss_hist[-1])\n",
    "    \n",
    "    # evaluating model\n",
    "    if epoch % EVAL_FREQ == 0:\n",
    "        accuracy, valid_loss = eval_model(cnn)  \n",
    "        print(f\"Accuracy at epoch {epoch}: {round(accuracy, 2)}%\")\n",
    "    else:   \n",
    "        accuracy, valid_loss = -1, -1\n",
    "    stats[\"accuracy\"].append(accuracy)\n",
    "    stats[\"valid_loss\"].append(valid_loss)\n",
    "    \n",
    "    # saving checkpoint\n",
    "    if epoch % SAVE_FREQ == 0:\n",
    "        save_model(model=cnn, optimizer=optimizer, epoch=epoch, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, _ = eval_model(cnn)  \n",
    "print(f\"Classification accuracy: {round(accuracy, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.array(stats[\"epoch\"])\n",
    "train_loss = np.array(stats[\"train_loss\"])\n",
    "\n",
    "eval_loss = np.array(stats[\"valid_loss\"])\n",
    "accuracy = np.array(stats[\"accuracy\"])\n",
    "eval_idx = np.where(eval_loss != -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(16,5)\n",
    "\n",
    "for a in ax:\n",
    "\n",
    "    a.plot(epochs+1, train_loss, label=\"Train Loss\", linewidth=3)\n",
    "    a.plot(epochs[eval_idx]+1, eval_loss[eval_idx], c=\"red\", label=\"Eval Loss\", linewidth=3)\n",
    "#     a.scatter(epochs[eval_idx]+1, eval_loss[eval_idx], c=\"red\", s=100, marker=\"x\")\n",
    "    a.legend(loc=\"best\")\n",
    "    a.set_xlabel(\"Epochs\")\n",
    "    a.set_ylabel(\"CE Loss value\")\n",
    "\n",
    "ax[0].set_title(\"Training-Eval Progress\")\n",
    "ax[1].set_title(\"Training-Eval Progress (Log)\")\n",
    "ax[1].set_yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(f, K=5):\n",
    "    \"\"\" Smoothing a function using a low-pass filter (mean) of size K \"\"\"\n",
    "    kernel = np.ones(K) / K\n",
    "    f = np.concatenate([f[:int(K//2)], f, f[int(-K//2):]])  # to account for boundaries\n",
    "    smooth_f = np.convolve(f, kernel, mode=\"same\")\n",
    "    smooth_f = smooth_f[K//2: -K//2]  # removing boundary-fixes\n",
    "    return smooth_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(16,5)\n",
    "\n",
    "ax[0].plot(epochs[eval_idx]+1, accuracy[eval_idx], c=\"red\", label=\"Accuracy\", linewidth=3)\n",
    "ax[0].legend(loc=\"best\")\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Classification Accuracy\")\n",
    "ax[0].set_title(\"Eval Accuracy Progress\")\n",
    "\n",
    "zoomed = accuracy[10:]\n",
    "filtered = smooth(zoomed, K=9)\n",
    "\n",
    "ax[1].plot(epochs[10:]+1, accuracy[10:], c=\"red\", label=\"Accuracy\", linewidth=3)\n",
    "ax[1].plot(epochs[10:]+1, filtered, c=\"blue\", label=\"Smoothed Accuracy\", linewidth=3)\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Classification Accuracy\")\n",
    "ax[1].set_title(\"Eval Accuracy Progress Focused on Flat Area\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "- Train and compare the MLP from Assignment 2 and a simple CNN on the SVHN dataset (available in PyTorch) with optimized hyper-parameters\n",
    "- Visualize several convolutional kernels and their activations\n",
    "- Train CNNs with L1, L2, Elastic regularization and No-Regularization. Which method achieves the best results?\n",
    "compare the model performance. With which regularization do you obtain the best results?\n",
    "- Train CNNs with and without Dropout. Compare the results: accuracy, training time, number of parameters, ...\n",
    "- Extra Point:\n",
    "  - Train CNNs with the following Pooling methods: MaxPooling, AvgPooling or a combination of both and compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Due Date**: Sunday 30th May at 23:59\n",
    "#### Submit it by mail using the subject: **CudaLab: Assignment3**\n",
    "####  Send me the following: Jupyter Notebook after running, Jupyter export as html, any other .py files or images used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    " - https://www.deeplearningbook.org/\n",
    " - http://cs231n.stanford.edu/\n",
    " - https://towardsdatascience.com/all-you-want-to-know-about-deep-learning-8d68dcffc258\n",
    " - https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\n",
    " - https://github.com/vdumoulin/conv_arithmetic\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=alert style=\"background-color:#F5F5F5; border-color:#C8C8C8\">\n",
    "    <b>Angel Villar-Corrales</b><br>\n",
    "    <ul>\n",
    "       <li> <b>Email</b>: villar@ais.uni-bonn.de\n",
    "       <li> <b>Website</b>: angelvillarcorrales.com\n",
    "    </ul>\n",
    "</div> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
